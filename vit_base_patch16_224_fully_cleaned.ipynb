{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEzY81bRHoT7",
    "outputId": "c4d73934-b360-4635-9341-799d90c96c4e"
   },
   "outputs": [],
   "source": [
    "! kaggle datasets download mahaveersuryavanshi/datasetb-chilli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qUA8bVqHHrsm",
    "outputId": "aae14435-e7cc-4be7-ac55-dba3e06ab4e9"
   },
   "outputs": [],
   "source": [
    "!unzip /content/datasetb-chilli.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B04E9sWrP4Cl"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "class VisionTransformerFramework_fineTuned:\n",
    "    def __init__(self, model_name, num_classes=3, device='cuda'):\n",
    "        self.model_name = model_name\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "        in_features = self.model.get_classifier().in_features\n",
    "        self.model.reset_classifier(num_classes=num_classes)\n",
    "\n",
    "        self.freeze_layers(\"backbone\")\n",
    "\n",
    "        head_params = list(self.model.get_classifier().parameters())\n",
    "        backbone_params = [p for n, p in self.model.named_parameters() if \"head\" not in n and p.requires_grad]\n",
    "\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "            {'params': backbone_params, 'lr': 1e-5},\n",
    "            {'params': head_params, 'lr': 1e-3}\n",
    "        ])\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.train_losses, self.val_losses = [], []\n",
    "        self.train_accuracies, self.val_accuracies = [], []\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def freeze_layers(self, freeze_until: str = \"all\"):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if freeze_until == \"all\":\n",
    "                param.requires_grad = False\n",
    "            elif freeze_until == \"none\":\n",
    "                param.requires_grad = True\n",
    "            elif freeze_until == \"backbone\":\n",
    "                param.requires_grad = \"head\" in name or \"fc\" in name\n",
    "\n",
    "    def train(self, train_loader, val_loader, epochs=20, early_stopping_patience=5):\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=epochs)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            train_loss, correct, total = 0, 0, 0\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            train_acc = 100 * correct / total\n",
    "            val_loss, val_acc = self.evaluate(val_loader)\n",
    "\n",
    "            self.train_losses.append(train_loss / len(train_loader))\n",
    "            self.train_accuracies.append(train_acc)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_accuracies.append(val_acc)\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}%\")\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= early_stopping_patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        print(\"Training complete in {:.2f}s\".format(time.time() - start_time))\n",
    "        self.plot_training_metrics()\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        val_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        return val_loss / len(loader), 100 * correct / total\n",
    "\n",
    "    def test(self, test_loader, class_names):\n",
    "        self.model.eval()\n",
    "        all_preds, all_labels, all_probs = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(probs.data, 1)\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "        print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "        self._plot_confusion_matrix(all_labels, all_preds, class_names)\n",
    "        self._plot_auc_roc(all_labels, all_probs, class_names)\n",
    "        self._plot_tsne(np.array(all_probs), np.array(all_labels), class_names)\n",
    "        self._plot_precision_recall_f1(all_labels, all_preds, class_names)\n",
    "\n",
    "        acc = 100 * np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
    "        print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    def _plot_confusion_matrix(self, labels, preds, class_names):\n",
    "        cm = confusion_matrix(labels, preds)\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"confusion_matrix.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_auc_roc(self, labels, probs, class_names):\n",
    "        try:\n",
    "            auc = roc_auc_score(labels, probs, multi_class='ovr')\n",
    "            print(f\"AUC Score: {auc:.4f}\")\n",
    "            for i in range(len(class_names)):\n",
    "                fpr, tpr, _ = roc_curve(np.array(labels) == i, np.array(probs)[:, i])\n",
    "                plt.plot(fpr, tpr, label=f'{class_names[i]}')\n",
    "            plt.title(\"AUC-ROC Curve\")\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\"auc_roc_curve.png\")\n",
    "            plt.show()\n",
    "        except ValueError:\n",
    "            print(\"ROC curve could not be calculated. Check class distribution.\")\n",
    "\n",
    "    def _plot_tsne(self, features, labels, class_names):\n",
    "        tsne = TSNE(n_components=2, perplexity=30, n_iter=300, random_state=42)\n",
    "        result = tsne.fit_transform(features)\n",
    "        labels = np.array(labels)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for i in np.unique(labels):\n",
    "            idx = labels == i\n",
    "            plt.scatter(result[idx, 0], result[idx, 1], label=class_names[i], alpha=0.7)\n",
    "        plt.title(\"t-SNE of Output Features\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"tsne_plot.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_precision_recall_f1(self, labels, preds, class_names):\n",
    "        report = classification_report(labels, preds, target_names=class_names, output_dict=True)\n",
    "        metrics = ['precision', 'recall', 'f1-score']\n",
    "        for metric in metrics:\n",
    "            values = [report[cls][metric] for cls in class_names]\n",
    "            plt.figure()\n",
    "            sns.barplot(x=class_names, y=values)\n",
    "            plt.title(f'{metric.capitalize()} per Class')\n",
    "            plt.ylim(0, 1)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{metric}_per_class.png')\n",
    "            plt.show()\n",
    "\n",
    "    def plot_training_metrics(self):\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.train_losses, label='Train Loss')\n",
    "        plt.plot(self.val_losses, label='Val Loss')\n",
    "        plt.title(\"Loss Curve\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.train_accuracies, label='Train Acc')\n",
    "        plt.plot(self.val_accuracies, label='Val Acc')\n",
    "        plt.title(\"Accuracy Curve\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"training_metrics.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_first_layer_filters(self):\n",
    "        for layer in self.model.modules():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                filters = layer.weight.data.clone().cpu()\n",
    "                break\n",
    "        else:\n",
    "            print(\"No Conv2D layer found.\")\n",
    "            return\n",
    "\n",
    "        n_filters = min(16, filters.shape[0])\n",
    "        fig, axs = plt.subplots(1, n_filters, figsize=(20, 5))\n",
    "        for i in range(n_filters):\n",
    "            axs[i].imshow(filters[i][0], cmap='gray')\n",
    "            axs[i].axis('off')\n",
    "        plt.suptitle(\"First Conv Layer Filters\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"first_layer_filters.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_first_layer_activations(self, image_tensor):\n",
    "        activation = {}\n",
    "\n",
    "        def hook_fn(module, input, output):\n",
    "            activation['act'] = output.detach()\n",
    "\n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                module.register_forward_hook(hook_fn)\n",
    "                break\n",
    "\n",
    "        _ = self.model(image_tensor.unsqueeze(0).to(self.device))\n",
    "        act = activation['act'].squeeze().cpu()\n",
    "        fig, axs = plt.subplots(1, min(8, act.shape[0]), figsize=(20, 5))\n",
    "        for i in range(min(8, act.shape[0])):\n",
    "            axs[i].imshow(act[i], cmap='viridis')\n",
    "            axs[i].axis('off')\n",
    "        plt.suptitle(\"Activations from First Conv Layer\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"first_layer_activations.png\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYAJpYgaIBrJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Example dataset path (use your own)\n",
    "train_dataset = datasets.ImageFolder('/content/DatasetB_split_zip/train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder('/content/DatasetB_split_zip/val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder('/content/DatasetB_split_zip/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Class names\n",
    "class_names = train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYmeCvv0JV19"
   },
   "outputs": [],
   "source": [
    "# Replace with your model name and num_classes\n",
    "model_name = 'vit_base_patch16_224'  # or any of the supported models\n",
    "num_classes = 3\n",
    "framework = VisionTransformerFramework_fineTuned(model_name=model_name, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "RhwsXakJJoRY",
    "outputId": "dc42cbd9-c5aa-4490-ccaa-13019fb416e1"
   },
   "outputs": [],
   "source": [
    "framework.train(train_loader, val_loader, epochs=30, early_stopping_patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0HDgMYEQOsCu",
    "outputId": "6cc3e8f0-dc31-4458-b5ba-68ae881eb194"
   },
   "outputs": [],
   "source": [
    "class_names = ['Aphids', 'Healthy', 'Mitesthrips']  # Modify based on your dataset\n",
    "framework.test(test_loader, class_names=class_names)\n",
    "\n",
    "framework.visualize_first_layer_filters()\n",
    "\n",
    "sample_image, _ = next(iter(test_loader))  # get a batch\n",
    "framework.visualize_first_layer_activations(sample_image[0])  # visualize first image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBt26T-pUUMK"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "class VisionTransformerFramework_fineTuned_2:\n",
    "    def __init__(self, model_name, num_classes=3, device='cuda'):\n",
    "        self.model_name = model_name\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = timm.create_model(model_name, pretrained=True, num_classes=num_classes, drop_rate=0.5)\n",
    "\n",
    "        self.freeze_layers(\"none\")  # Fine-tune all layers\n",
    "\n",
    "        head_params = list(self.model.get_classifier().parameters())\n",
    "        backbone_params = [p for n, p in self.model.named_parameters() if \"head\" not in n and p.requires_grad]\n",
    "\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "            {'params': backbone_params, 'lr': 1e-5, 'weight_decay': 1e-4},\n",
    "            {'params': head_params, 'lr': 1e-4, 'weight_decay': 1e-4}\n",
    "        ])\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "        self.train_losses, self.val_losses = [], []\n",
    "        self.train_accuracies, self.val_accuracies = [], []\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def freeze_layers(self, freeze_until: str = \"none\"):\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def train(self, train_loader, val_loader, epochs=30, early_stopping_patience=5):\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=epochs)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            train_loss, correct, total = 0, 0, 0\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            train_acc = 100 * correct / total\n",
    "            val_loss, val_acc = self.evaluate(val_loader)\n",
    "\n",
    "            self.train_losses.append(train_loss / len(train_loader))\n",
    "            self.train_accuracies.append(train_acc)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_accuracies.append(val_acc)\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "                  f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}%\")\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= early_stopping_patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        print(\"Training complete in {:.2f}s\".format(time.time() - start_time))\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        val_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        return val_loss / len(loader), 100 * correct / total\n",
    "\n",
    "    def test(self, test_loader, class_names):\n",
    "        self.model.eval()\n",
    "        all_preds, all_labels, all_probs = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(probs.data, 1)\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "        print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "        self._plot_confusion_matrix(all_labels, all_preds, class_names)\n",
    "        self._plot_auc_roc(all_labels, all_probs, class_names)\n",
    "        self._plot_tsne(np.array(all_probs), np.array(all_labels), class_names)\n",
    "        self._plot_precision_recall_f1(all_labels, all_preds, class_names)\n",
    "\n",
    "        acc = 100 * np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
    "        print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    def _plot_confusion_matrix(self, labels, preds, class_names):\n",
    "        cm = confusion_matrix(labels, preds)\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_auc_roc(self, labels, probs, class_names):\n",
    "        labels = np.array(labels)\n",
    "        probs = np.array(probs)\n",
    "        try:\n",
    "            auc = roc_auc_score(labels, probs, multi_class='ovr')\n",
    "            print(f\"AUC Score: {auc:.4f}\")\n",
    "            for i in range(len(class_names)):\n",
    "                fpr, tpr, _ = roc_curve(labels == i, probs[:, i])\n",
    "                plt.plot(fpr, tpr, label=f'{class_names[i]}')\n",
    "            plt.title(\"AUC-ROC Curve\")\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        except ValueError:\n",
    "            print(\"ROC curve could not be calculated. Check class distribution.\")\n",
    "\n",
    "    def _plot_tsne(self, features, labels, class_names):\n",
    "        tsne = TSNE(n_components=2, perplexity=30, n_iter=300, random_state=42)\n",
    "        result = tsne.fit_transform(features)\n",
    "        labels = np.array(labels)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for i in np.unique(labels):\n",
    "            idx = labels == i\n",
    "            plt.scatter(result[idx, 0], result[idx, 1], label=class_names[i], alpha=0.7)\n",
    "        plt.title(\"t-SNE of Output Features\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_precision_recall_f1(self, labels, preds, class_names):\n",
    "        report = classification_report(labels, preds, target_names=class_names, output_dict=True)\n",
    "        metrics = ['precision', 'recall', 'f1-score']\n",
    "        for metric in metrics:\n",
    "            values = [report[cls][metric] for cls in class_names]\n",
    "            plt.figure()\n",
    "            sns.barplot(x=class_names, y=values)\n",
    "            plt.title(f'{metric.capitalize()} per Class')\n",
    "            plt.ylim(0, 1)\n",
    "            plt.show()\n",
    "\n",
    "    def plot_training_metrics(self):\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.train_losses, label='Train Loss')\n",
    "        plt.plot(self.val_losses, label='Val Loss')\n",
    "        plt.title(\"Loss Curve\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.train_accuracies, label='Train Acc')\n",
    "        plt.plot(self.val_accuracies, label='Val Acc')\n",
    "        plt.title(\"Accuracy Curve\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_first_layer_filters(self):\n",
    "        for layer in self.model.modules():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                filters = layer.weight.data.clone().cpu()\n",
    "                break\n",
    "        else:\n",
    "            print(\"No Conv2D layer found.\")\n",
    "            return\n",
    "\n",
    "        n_filters = min(16, filters.shape[0])\n",
    "        fig, axs = plt.subplots(1, n_filters, figsize=(20, 5))\n",
    "        for i in range(n_filters):\n",
    "            axs[i].imshow(filters[i][0], cmap='gray')\n",
    "            axs[i].axis('off')\n",
    "        plt.suptitle(\"First Conv Layer Filters\")\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_first_layer_activations(self, image_tensor):\n",
    "        activation = {}\n",
    "\n",
    "        def hook_fn(module, input, output):\n",
    "            activation['act'] = output.detach()\n",
    "\n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                module.register_forward_hook(hook_fn)\n",
    "                break\n",
    "\n",
    "        _ = self.model(image_tensor.unsqueeze(0).to(self.device))\n",
    "        act = activation['act'].squeeze().cpu()\n",
    "        fig, axs = plt.subplots(1, min(8, act.shape[0]), figsize=(20, 5))\n",
    "        for i in range(min(8, act.shape[0])):\n",
    "            axs[i].imshow(act[i], cmap='viridis')\n",
    "            axs[i].axis('off')\n",
    "        plt.suptitle(\"Activations from First Conv Layer\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUnc6MfuUdVF"
   },
   "outputs": [],
   "source": [
    "# Replace with your model name and num_classes\n",
    "model_name = 'vit_base_patch16_224'  # or any of the supported models\n",
    "num_classes = 3\n",
    "framework_2 = VisionTransformerFramework_fineTuned_2(model_name=model_name, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8N6W-3cUyUA",
    "outputId": "e7b09b59-b790-45ec-8dcb-03852987a6e2"
   },
   "outputs": [],
   "source": [
    "framework_2.train(train_loader, val_loader, epochs=30, early_stopping_patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RdmYzr9na5Ol",
    "outputId": "6a1eaef4-4523-4429-c551-03eedfb4167f"
   },
   "outputs": [],
   "source": [
    "class_names = ['Aphids', 'Healthy', 'Mitesthrips']  # Modify based on your dataset\n",
    "framework.test(test_loader, class_names=class_names)\n",
    "\n",
    "framework.visualize_first_layer_filters()\n",
    "\n",
    "sample_image, _ = next(iter(test_loader))  # get a batch\n",
    "framework.visualize_first_layer_activations(sample_image[0])  # visualize first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltXr8vckdrmK"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "class VisionTransformerFramework_fineTuned1:\n",
    "    def __init__(self, model_name, num_classes=3, device='cuda'):\n",
    "        self.model_name = model_name\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "        in_features = self.model.get_classifier().in_features\n",
    "        self.model.reset_classifier(num_classes=num_classes)\n",
    "\n",
    "        trainable = [name for name, p in self.model.named_parameters() if p.requires_grad]\n",
    "        if not trainable:\n",
    "          raise RuntimeError(\"No trainable parameters found. Check your freeze_layers logic.\")\n",
    "        else:\n",
    "          print(f\"Trainable params: {len(trainable)}\")\n",
    "\n",
    "        # self.freeze_layers(\"custom\",9)\n",
    "        self.freeze_layers(\"custom\",5)\n",
    "        # self.freeze_layers(\"custom\",4)\n",
    "        # self.freeze_layers(\"custom\",7)\n",
    "        # self.freeze_layers(\"head_only\")\n",
    "\n",
    "        head_params = list(self.model.get_classifier().parameters())\n",
    "        backbone_params = [p for n, p in self.model.named_parameters() if \"head\" not in n and p.requires_grad]\n",
    "\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "            {'params': backbone_params, 'lr': 1e-5},\n",
    "            {'params': head_params, 'lr': 1e-3}\n",
    "        ])\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.train_losses, self.val_losses = [], []\n",
    "        self.train_accuracies, self.val_accuracies = [], []\n",
    "        self.model.to(self.device)\n",
    "    def freeze_layers(self, strategy: str = \"all\", unfreeze_from_block: int = None):\n",
    "      \"\"\"\n",
    "      strategy: \"all\", \"none\", \"head_only\", \"custom\"\n",
    "      unfreeze_from_block: for \"custom\", unfreeze from a certain block number (e.g., 9 means last 3 blocks in ViT-B/16)\n",
    "      \"\"\"\n",
    "      if strategy == \"none\":\n",
    "        # Unfreeze all\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "      elif strategy == \"all\":\n",
    "        # Freeze all\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "      elif strategy == \"head_only\":\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if \"head\" in name or \"fc\" in name:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "      elif strategy == \"custom\":\n",
    "        for name, param in self.model.named_parameters():\n",
    "            param.requires_grad = False  # Default to frozen\n",
    "\n",
    "            if \"head\" in name or \"fc\" in name:\n",
    "                param.requires_grad = True  # Always unfreeze head\n",
    "\n",
    "            if unfreeze_from_block is not None:\n",
    "                # Example: unfreeze blocks.9 to blocks.11\n",
    "                for i in range(unfreeze_from_block, 12):  # assuming 12 transformer blocks\n",
    "                    if f\"blocks.{i}\" in name:\n",
    "                        param.requires_grad = True\n",
    "\n",
    "                # Also unfreeze norm/pre_logits layers if they exist\n",
    "                if any(x in name for x in [\"norm\", \"pre_logits\"]):\n",
    "                    param.requires_grad = True\n",
    "\n",
    "\n",
    "    def train(self, train_loader, val_loader, epochs=20, early_stopping_patience=5):\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=epochs)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            train_loss, correct, total = 0, 0, 0\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            train_acc = 100 * correct / total\n",
    "            val_loss, val_acc = self.evaluate(val_loader)\n",
    "\n",
    "            self.train_losses.append(train_loss / len(train_loader))\n",
    "            self.train_accuracies.append(train_acc)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_accuracies.append(val_acc)\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}%\")\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= early_stopping_patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        print(\"Training complete in {:.2f}s\".format(time.time() - start_time))\n",
    "        self.plot_training_metrics()\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        val_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        return val_loss / len(loader), 100 * correct / total\n",
    "\n",
    "    def test(self, test_loader, class_names):\n",
    "        self.model.eval()\n",
    "        all_preds, all_labels, all_probs = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(probs.data, 1)\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "        print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "        self._plot_confusion_matrix(all_labels, all_preds, class_names)\n",
    "        self._plot_auc_roc(all_labels, all_probs, class_names)\n",
    "        self._plot_tsne(np.array(all_probs), np.array(all_labels), class_names)\n",
    "        self._plot_precision_recall_f1(all_labels, all_preds, class_names)\n",
    "\n",
    "        acc = 100 * np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
    "        print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    def _plot_confusion_matrix(self, labels, preds, class_names):\n",
    "        cm = confusion_matrix(labels, preds)\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"confusion_matrix.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_auc_roc(self, labels, probs, class_names):\n",
    "        try:\n",
    "            auc = roc_auc_score(labels, probs, multi_class='ovr')\n",
    "            print(f\"AUC Score: {auc:.4f}\")\n",
    "            for i in range(len(class_names)):\n",
    "                fpr, tpr, _ = roc_curve(np.array(labels) == i, np.array(probs)[:, i])\n",
    "                plt.plot(fpr, tpr, label=f'{class_names[i]}')\n",
    "            plt.title(\"AUC-ROC Curve\")\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\"auc_roc_curve.png\")\n",
    "            plt.show()\n",
    "        except ValueError:\n",
    "            print(\"ROC curve could not be calculated. Check class distribution.\")\n",
    "\n",
    "    def _plot_tsne(self, features, labels, class_names):\n",
    "        tsne = TSNE(n_components=2, perplexity=30, n_iter=300, random_state=42)\n",
    "        result = tsne.fit_transform(features)\n",
    "        labels = np.array(labels)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for i in np.unique(labels):\n",
    "            idx = labels == i\n",
    "            plt.scatter(result[idx, 0], result[idx, 1], label=class_names[i], alpha=0.7)\n",
    "        plt.title(\"t-SNE of Output Features\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"tsne_plot.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_precision_recall_f1(self, labels, preds, class_names):\n",
    "        report = classification_report(labels, preds, target_names=class_names, output_dict=True)\n",
    "        metrics = ['precision', 'recall', 'f1-score']\n",
    "        for metric in metrics:\n",
    "            values = [report[cls][metric] for cls in class_names]\n",
    "            plt.figure()\n",
    "            sns.barplot(x=class_names, y=values)\n",
    "            plt.title(f'{metric.capitalize()} per Class')\n",
    "            plt.ylim(0, 1)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{metric}_per_class.png')\n",
    "            plt.show()\n",
    "\n",
    "    def plot_training_metrics(self):\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.train_losses, label='Train Loss')\n",
    "        plt.plot(self.val_losses, label='Val Loss')\n",
    "        plt.title(\"Loss Curve\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.train_accuracies, label='Train Acc')\n",
    "        plt.plot(self.val_accuracies, label='Val Acc')\n",
    "        plt.title(\"Accuracy Curve\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"training_metrics.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_first_layer_filters(self):\n",
    "        for layer in self.model.modules():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                filters = layer.weight.data.clone().cpu()\n",
    "                break\n",
    "        else:\n",
    "            print(\"No Conv2D layer found.\")\n",
    "            return\n",
    "\n",
    "        n_filters = min(16, filters.shape[0])\n",
    "        fig, axs = plt.subplots(1, n_filters, figsize=(20, 5))\n",
    "        for i in range(n_filters):\n",
    "            axs[i].imshow(filters[i][0], cmap='gray')\n",
    "            axs[i].axis('off')\n",
    "        plt.suptitle(\"First Conv Layer Filters\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"first_layer_filters.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_first_layer_activations(self, image_tensor):\n",
    "        activation = {}\n",
    "\n",
    "        def hook_fn(module, input, output):\n",
    "            activation['act'] = output.detach()\n",
    "\n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                module.register_forward_hook(hook_fn)\n",
    "                break\n",
    "\n",
    "        _ = self.model(image_tensor.unsqueeze(0).to(self.device))\n",
    "        act = activation['act'].squeeze().cpu()\n",
    "        fig, axs = plt.subplots(1, min(8, act.shape[0]), figsize=(20, 5))\n",
    "        for i in range(min(8, act.shape[0])):\n",
    "            axs[i].imshow(act[i], cmap='viridis')\n",
    "            axs[i].axis('off')\n",
    "        plt.suptitle(\"Activations from First Conv Layer\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"first_layer_activations.png\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpf-piZVpKzN"
   },
   "source": [
    "**Unfreeze last 3 transformer blocks (blocks.9, blocks.10, blocks.11)\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDdHxeUXeA5c",
    "outputId": "839fa6b5-b7d9-49e3-a20e-3126aff042ab"
   },
   "outputs": [],
   "source": [
    "# Replace with your model name and num_classes\n",
    "model_name = 'vit_base_patch16_224'  # or any of the supported models\n",
    "num_classes = 3\n",
    "framework = VisionTransformerFramework_fineTuned1(model_name=model_name, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "_JdlmRuMeRAy",
    "outputId": "ff773aac-b560-44ac-94aa-aa71289332a3"
   },
   "outputs": [],
   "source": [
    "framework.train(train_loader, val_loader, epochs=30, early_stopping_patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "---c2CPtoia0",
    "outputId": "3b26fe83-714b-46a5-8b27-68e93f5fc44f"
   },
   "outputs": [],
   "source": [
    "class_names = ['Aphids', 'Healthy', 'Mitesthrips']  # Modify based on your dataset\n",
    "framework.test(test_loader, class_names=class_names)\n",
    "\n",
    "framework.visualize_first_layer_filters()\n",
    "\n",
    "sample_image, _ = next(iter(test_loader))  # get a batch\n",
    "framework.visualize_first_layer_activations(sample_image[0])  # visualize first image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "005IXp-Yto9B"
   },
   "source": [
    "**Unfreeze last 7 transformer blocks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JkYFx9n4ppw0",
    "outputId": "e9d163c2-4325-4dd2-f599-8a337e050261"
   },
   "outputs": [],
   "source": [
    "# Replace with your model name and num_classes\n",
    "model_name = 'vit_base_patch16_224'  # or any of the supported models\n",
    "num_classes = 3\n",
    "framework_4 = VisionTransformerFramework_fineTuned1(model_name=model_name, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "id": "UZHYdSw_pxzy",
    "outputId": "0b701a09-b321-4103-f3d8-544490cdaf0b"
   },
   "outputs": [],
   "source": [
    "framework_4.train(train_loader, val_loader, epochs=30, early_stopping_patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zK7ySYsus5FS",
    "outputId": "26c4dcc5-d44f-4d73-bfef-c7cf4180f9aa"
   },
   "outputs": [],
   "source": [
    "class_names = ['Aphids', 'Healthy', 'Mitesthrips']  # Modify based on your dataset\n",
    "framework_4.test(test_loader, class_names=class_names)\n",
    "\n",
    "framework_4.visualize_first_layer_filters()\n",
    "\n",
    "sample_image, _ = next(iter(test_loader))  # get a batch\n",
    "framework_4.visualize_first_layer_activations(sample_image[0])  # visualize first image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYNYY3rqz9QF"
   },
   "source": [
    "**unfreeze 8 layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8MpBpqeuEJO",
    "outputId": "bc8f14a5-53e4-4972-b15b-0aef2b02a04b"
   },
   "outputs": [],
   "source": [
    "# Replace with your model name and num_classes\n",
    "model_name = 'vit_base_patch16_224'  # or any of the supported models\n",
    "num_classes = 3\n",
    "framework_5 = VisionTransformerFramework_fineTuned1(model_name=model_name, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "SjHyQwRYuHkk",
    "outputId": "55330766-107c-45c6-df03-b0f76253ca6e"
   },
   "outputs": [],
   "source": [
    "framework_5.train(train_loader, val_loader, epochs=30, early_stopping_patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "x1N6rDoLxxeo",
    "outputId": "c6dd0139-5863-45d3-8486-72b5849477d2"
   },
   "outputs": [],
   "source": [
    "class_names = ['Aphids', 'Healthy', 'Mitesthrips']  # Modify based on your dataset\n",
    "framework_5.test(test_loader, class_names=class_names)\n",
    "\n",
    "framework_5.visualize_first_layer_filters()\n",
    "\n",
    "sample_image, _ = next(iter(test_loader))  # get a batch\n",
    "framework_5.visualize_first_layer_activations(sample_image[0])  # visualize first image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B20p_T7-3qC2"
   },
   "source": [
    "**unfreeze 5 layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SR__N8n00UC7",
    "outputId": "6c264e3c-90ae-48a9-9623-df527421db4e"
   },
   "outputs": [],
   "source": [
    "# Replace with your model name and num_classes\n",
    "model_name = 'vit_base_patch16_224'  # or any of the supported models\n",
    "num_classes = 3\n",
    "framework_6 = VisionTransformerFramework_fineTuned1(model_name=model_name, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "MlrSWEx60aaE",
    "outputId": "a9e9d5a1-0936-4e03-a925-6a185303ebff"
   },
   "outputs": [],
   "source": [
    "framework_6.train(train_loader, val_loader, epochs=30, early_stopping_patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "w1omm7t_3TfT",
    "outputId": "1bbadd9d-408b-4350-d6d4-5305690079cf"
   },
   "outputs": [],
   "source": [
    "class_names = ['Aphids', 'Healthy', 'Mitesthrips']  # Modify based on your dataset\n",
    "framework_6.test(test_loader, class_names=class_names)\n",
    "\n",
    "framework_6.visualize_first_layer_filters()\n",
    "\n",
    "sample_image, _ = next(iter(test_loader))  # get a batch\n",
    "framework_6.visualize_first_layer_activations(sample_image[0])  # visualize first image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIPrtzFo_O-0"
   },
   "source": [
    "**train only classifier head**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Xx3X4Qz4kMa",
    "outputId": "b9e36891-7f66-4421-c2ef-6696ae3f26e2"
   },
   "outputs": [],
   "source": [
    "# Replace with your model name and num_classes\n",
    "model_name = 'vit_base_patch16_224'  # or any of the supported models\n",
    "num_classes = 3\n",
    "framework_7 = VisionTransformerFramework_fineTuned1(model_name=model_name, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "id": "TccXFE414ohF",
    "outputId": "11ac1583-0db5-48e6-9be4-1213cbaa14e9"
   },
   "outputs": [],
   "source": [
    "framework_7.train(train_loader, val_loader, epochs=30, early_stopping_patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "R1mXnWzz7L9F",
    "outputId": "0f599346-ed8a-4178-86cb-77fad16e7b47"
   },
   "outputs": [],
   "source": [
    "class_names = ['Aphids', 'Healthy', 'Mitesthrips']  # Modify based on your dataset\n",
    "framework_7.test(test_loader, class_names=class_names)\n",
    "\n",
    "framework_7.visualize_first_layer_filters()\n",
    "\n",
    "sample_image, _ = next(iter(test_loader))  # get a batch\n",
    "framework_7.visualize_first_layer_activations(sample_image[0])  # visualize first image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycdwfEURxie3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_dataset = datasets.ImageFolder('/content/DatasetB_split_zip/val', transform=val_test_transform)\n",
    "test_dataset = datasets.ImageFolder('/content/DatasetB_split_zip/test', transform=val_test_transform)\n",
    "\n",
    "\n",
    "# Example dataset path (use your own)\n",
    "train_dataset = datasets.ImageFolder('/content/DatasetB_split_zip/train', transform=train_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Class names\n",
    "class_names = train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190,
     "referenced_widgets": [
      "d244472ff081438e8f6c4fb2efcf3ec9",
      "d0962f4a1c484a0c8aecb33d63bff7fe",
      "37b39f74717c430b8f1d0dd5a982f2a2",
      "5ece8c4b8af34ab298b06ddd7fa7079b",
      "3ab5c297b70a417592141bc1ff3b349f",
      "6030710b29c943a7b76a8a88386cf5e8",
      "4894b0f2528a40acb47efa65e5a23605",
      "e0d81e8ba0ac447e9489b804fef00f82",
      "e63de9c2b02048de9a0fe04acbcbd02b",
      "625125de3619483ba7278c9d9e5fe258",
      "3307a1ac47d64c53849bb72b421f5821"
     ]
    },
    "id": "XJ8li9Zvx83r",
    "outputId": "8a2f1ee3-08cb-4d5a-fb74-9d6935e4aa8f"
   },
   "outputs": [],
   "source": [
    "# Replace with your model name and num_classes\n",
    "model_name = 'vit_base_patch16_224'  # or any of the supported models\n",
    "num_classes = 3\n",
    "framework = VisionTransformerFramework_fineTuned1(model_name=model_name, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "id": "Ld6YOqDiyFa3",
    "outputId": "e8cd54ff-504c-4903-c523-f8114d56556e"
   },
   "outputs": [],
   "source": [
    "framework.train(train_loader, val_loader, epochs=30, early_stopping_patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zG3bzFpl3O1W",
    "outputId": "395039c6-c095-4714-8405-23fe99b8a435"
   },
   "outputs": [],
   "source": [
    "class_names = ['Aphids', 'Healthy', 'Mitesthrips']  # Modify based on your dataset\n",
    "framework.test(test_loader, class_names=class_names)\n",
    "\n",
    "framework.visualize_first_layer_filters()\n",
    "\n",
    "sample_image, _ = next(iter(test_loader))  # get a batch\n",
    "framework.visualize_first_layer_activations(sample_image[0])  # visualize first image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbstripout\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
